{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b94ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f1f8c2",
   "metadata": {},
   "source": [
    "# Function declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b991cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGameData(initialSeason,finalSeason):\n",
    "    '''\n",
    "    loadGameData loads each season of game data into a single table, with columns\n",
    "    Season, Visitor/Neutral, Home/Neutral, VisitorWin.\n",
    "    \n",
    "    Inputs: \n",
    "    initialSeason    :    first season (second year of season) to include (int)\n",
    "    finalSeason      :    last season to include (inclusive) (int)\n",
    "    \n",
    "    Outputs:\n",
    "    dataset          :    pandas dataframe of format described above\n",
    "    '''\n",
    "    seasonTables = [] # to store tables from each season\n",
    "    \n",
    "    # loop over and download each season's data\n",
    "    for season in range(initialSeason,finalSeason+1):\n",
    "        print('Dowloading',season,'season data...')\n",
    "        table = pd.read_hdf('pyData/games'+str(season)+'.h5','table')\n",
    "        table = table.reindex(columns=['Season','Visitor/Neutral','Home/Neutral','VisitorWin'])\n",
    "        seasonStr = str(season)\n",
    "        table['Season'] = str(season-1)+'-'+seasonStr[2:4] # format season in same way as PCA\n",
    "        seasonTables.append(table)\n",
    "        print('##################################')\n",
    "    \n",
    "    dataset = pd.concat(seasonTables)\n",
    "    return dataset\n",
    "\n",
    "def generatePCAVectors(dataFile,seasonToExclude):\n",
    "    '''\n",
    "    generataPCAVectors creates the PCA vectors for a subset of the team season-average stat data.\n",
    "    \n",
    "    Inputs:\n",
    "    dataFile - name of the file containing every team's season-average stat data\n",
    "    seasonToExclude - season to be removed from data set\n",
    "    \n",
    "    Outputs:\n",
    "    statMean - mean of each statistical category included in dataset\n",
    "    topVectors - top 7 covariance vectors (rows - stat catgory; columns - index in decreasing eigenvalue order)\n",
    "    '''\n",
    "    # load data\n",
    "    dfTeamData = pd.read_hdf(dataFile)\n",
    "    dfTeamData = dfTeamData[dfTeamData['Season'] != seasonToExclude]\n",
    "    \n",
    "    # compute PCA vectors\n",
    "    teamDataMat = (dfTeamData.loc[:,'FG':'oppPTS']).to_numpy()\n",
    "    statMean = np.mean(teamDataMat,axis=0) # Mean subtraction\n",
    "    teamDataZero = teamDataMat - statMean\n",
    "    N = teamDataZero.shape[0]\n",
    "    covMat = 1/N*np.dot(teamDataZero.T,teamDataZero) # covariance matrix\n",
    "    covLam,covVec = np.linalg.eig(covMat) # diagonlize\n",
    "    inds = np.argsort(covLam) # get indexes of sorted eigenvalues\n",
    "    topVectors = covVec[:,inds[:-8:-1]] #  covariance eigenvectors of top 7 eigenvalues\n",
    "    \n",
    "    # return covariance eigenvectors and means of each stat category\n",
    "    return statMean,topVectors\n",
    "\n",
    "def generateInputOutputData(statMean,PCABasis,dataset,statDataFile):\n",
    "    '''\n",
    "    generateInputOutputData converts tables of NBA game outcomes into a NumPy matrix giving the PCA components of each\n",
    "    team and the outcome of the game as a 1 (visitor win) or 0.\n",
    "    \n",
    "    Inputs:\n",
    "    statMean - mean of each team season average statistical category\n",
    "    PCABasis - matrix whose columns are the PCA basis vectors\n",
    "    dataset - table (pd.DataFrame) of matchups and game outcomes\n",
    "    statDataFile - name of file containing team season average stats\n",
    "    \n",
    "    Outputs:\n",
    "    trainingData - matrix where each row is one game, and if n is number of PCA basis vectors, then\n",
    "                    - first n columns are visiting team's PCA components,\n",
    "                    - second n columns are home team's PCA components,\n",
    "                    - final column is 1.0 if visiting team won; 0 otherwise.\n",
    "    '''\n",
    "    # convert team stat data to data dictionary\n",
    "    dfTeamData = pd.read_hdf(statDataFile) # load team stat data\n",
    "    # convert CHH to CHO for (first year of) season <= 2001\n",
    "    seasonInts = dfTeamData['Season'].map(lambda x : int(x[0:4]))\n",
    "    teamAbbrev = dfTeamData['Tm']\n",
    "    dfTeamData.loc[(seasonInts <= 2001) & (teamAbbrev == 'CHH'),'Tm'] = 'CHO'\n",
    "    # proceed with data dictionary\n",
    "    seasonTm = dfTeamData[['Season','Tm']]\n",
    "    keys = list(seasonTm.itertuples(index=False,name=None)) # keys for stat data dictionary\n",
    "    teamDataMat = (dfTeamData.loc[:,'FG':'oppPTS']).to_numpy()\n",
    "    teamDataZero = teamDataMat - statMean\n",
    "    teamPCA = np.dot(teamDataZero,PCABasis) # values for stat data dictionary\n",
    "    teamDataDict = dict(zip(keys,teamPCA))\n",
    "    \n",
    "    # convert dataset to set of keys for each team and output values (1 if True, 0 otherwise)\n",
    "    seasonTmVis = dataset[['Season','Visitor/Neutral']]\n",
    "    x_aKeys = pd.Series(list(seasonTmVis.itertuples(index=False,name=None)),name='x_a')\n",
    "    seasonTmHom = dataset[['Season','Home/Neutral']]\n",
    "    x_bKeys = pd.Series(list(seasonTmHom.itertuples(index=False,name=None)),name='x_b')\n",
    "    y = (dataset['VisitorWin'].map(float)).to_numpy()\n",
    "    \n",
    "    \n",
    "    # convert keys and output values into a single matrix, each row containing each teams PCA components and the outcome \n",
    "    x_aPCA = np.stack(x_aKeys.map(teamDataDict))\n",
    "    x_bPCA = np.stack(x_bKeys.map(teamDataDict))\n",
    "    trainingData = np.vstack((x_aPCA.T,x_bPCA.T,y)).T\n",
    "\n",
    "    return trainingData\n",
    "\n",
    "def sigma(a):\n",
    "    '''sigmoid function'''\n",
    "    return 1./(1.+np.exp(-a))\n",
    "\n",
    "def wVel(w,t,x,y):\n",
    "    '''\n",
    "    wVel evaluates velocity dw/dt = -dE/dw of logistic model, where E is error function.\n",
    "    \n",
    "    Inputs:\n",
    "    t - current integration time\n",
    "    w - array of current values of logistic model parameters\n",
    "    x - matrix of training data predictors. each row is a different data point;\n",
    "        assume first column is all ones, remaining columns are values of predictor variables\n",
    "    y - array of training data outcomes    \n",
    "        \n",
    "    Outputs:\n",
    "    -dE/dw - velocity of parameters (-)\n",
    "    '''\n",
    "    sigmaN = sigma(np.dot(x,w))\n",
    "    dEdw = np.dot(x.T,sigmaN-y)\n",
    "    return -dEdw\n",
    "\n",
    "def logisticInt(w0,T,x,y):\n",
    "    '''\n",
    "    logisticInt performs gradient descent (dw/dt = -dE/dw) on the logistic regression model.\n",
    "    \n",
    "    Inputs:\n",
    "    w0 - initial set of parameters of the model\n",
    "    T - total time to integrate for\n",
    "    x - set of predictor data (each row is a different data point, first column is ones)\n",
    "    y - set of outcome data\n",
    "    \n",
    "    Outputs:\n",
    "    w - final parameters after integration\n",
    "    dEdw - gradient of error function at the end of integration\n",
    "    Et - value of error function as a function of time\n",
    "    tt - time steps\n",
    "    '''\n",
    "    # perform gradient descent\n",
    "    nSteps = 100\n",
    "    tt = np.linspace(0,T,nSteps+1)\n",
    "    wt = odeint(wVel,w0,tt,(x,y))\n",
    "    \n",
    "    # gather observables\n",
    "    w = wt[-1]\n",
    "    dEdw = -wVel(w,0,x,y)\n",
    "    # calculation of error as function of time\n",
    "    sigmaNT = sigma(wt @ x.T)\n",
    "    Et = -(np.dot(np.log(sigmaNT),y) + np.dot(np.log(1.-sigmaNT),1.-y))\n",
    "    \n",
    "    return w,dEdw,Et,tt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a738c5d",
   "metadata": {},
   "source": [
    "# Train Logistic regression model on 2001-02 to 2020-21 season data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b534d2",
   "metadata": {},
   "source": [
    "Run <code>loadGameData</code> to extract a table with all the training data, 2000-01 to 2019-20 seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cbdb630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dowloading 2002 season data...\n",
      "##################################\n",
      "Dowloading 2003 season data...\n",
      "##################################\n",
      "Dowloading 2004 season data...\n",
      "##################################\n",
      "Dowloading 2005 season data...\n",
      "##################################\n",
      "Dowloading 2006 season data...\n",
      "##################################\n",
      "Dowloading 2007 season data...\n",
      "##################################\n",
      "Dowloading 2008 season data...\n",
      "##################################\n",
      "Dowloading 2009 season data...\n",
      "##################################\n",
      "Dowloading 2010 season data...\n",
      "##################################\n",
      "Dowloading 2011 season data...\n",
      "##################################\n",
      "Dowloading 2012 season data...\n",
      "##################################\n",
      "Dowloading 2013 season data...\n",
      "##################################\n",
      "Dowloading 2014 season data...\n",
      "##################################\n",
      "Dowloading 2015 season data...\n",
      "##################################\n",
      "Dowloading 2016 season data...\n",
      "##################################\n",
      "Dowloading 2017 season data...\n",
      "##################################\n",
      "Dowloading 2018 season data...\n",
      "##################################\n",
      "Dowloading 2019 season data...\n",
      "##################################\n",
      "Dowloading 2020 season data...\n",
      "##################################\n",
      "Dowloading 2021 season data...\n",
      "##################################\n"
     ]
    }
   ],
   "source": [
    "dataset = loadGameData(2002,2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ea364",
   "metadata": {},
   "source": [
    "Create PCA vectors for the teams in these seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01442427",
   "metadata": {},
   "outputs": [],
   "source": [
    "statMean,topV = generatePCAVectors('pyData/regSeasonData.h5','2000-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632c3b25",
   "metadata": {},
   "source": [
    "Generate training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13ab504",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainingData = generateInputOutputData(statMean,topV,dataset,'pyData/regSeasonData.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb385fee",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9761b9ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = trainingData.shape[0] # # of data points\n",
    "x = np.hstack([np.ones((n,1)),trainingData[:,:-1]]) # training data\n",
    "y = trainingData[:,-1] # outcomes\n",
    "nw = x.shape[1]\n",
    "\n",
    "w0 = np.zeros((nw,)) # initial condition\n",
    "T = 1 # integration time\n",
    "\n",
    "w,dEdw,Et,tt = logisticInt(w0,T,x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68543983",
   "metadata": {},
   "source": [
    "Print model coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "651ac57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3840704  -0.01434259 -0.03438915  0.058654   -0.00311654 -0.11415171\n",
      "  0.02359393 -0.01524577  0.01094597  0.02315544 -0.06196125  0.00262423\n",
      "  0.12908761 -0.02927948  0.01771595]\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efa097a",
   "metadata": {},
   "source": [
    "Print statMean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01026a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 37.67788945  82.94857621   0.45416248   7.6681742   21.46046901\n",
      "   0.35549079  30.01524288  61.48693467   0.48955276  18.09296482\n",
      "  23.83366834   0.75986767  10.97889447  31.65527638  42.63031826\n",
      "  22.12512563   7.58308208   4.88425461  14.41055276  20.84706868\n",
      " 101.12026801  37.68492462  82.94907873   0.4541474    7.66834171\n",
      "  21.45862647   0.35648409  30.01490787  61.48944724   0.48927973\n",
      "  18.09564489  23.83433836   0.75940704  10.97554439  31.65661642\n",
      "  42.63350084  22.12579564   7.58442211   4.88509213  14.40871022\n",
      "  20.84572864 101.12713568]\n"
     ]
    }
   ],
   "source": [
    "print(statMean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9b3867",
   "metadata": {},
   "source": [
    "Print PCA basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd6442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
